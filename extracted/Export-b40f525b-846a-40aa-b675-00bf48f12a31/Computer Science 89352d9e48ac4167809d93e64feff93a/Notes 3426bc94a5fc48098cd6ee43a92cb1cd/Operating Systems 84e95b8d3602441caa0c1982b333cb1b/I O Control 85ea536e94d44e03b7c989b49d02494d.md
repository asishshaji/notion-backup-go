# I/O Control

Most I/O devices have a hardware component called controller `disk controller, USB controller`. The controller contains a small processor which can be issued commands from the host operating system through the system bus. When the device completes a request, it triggers an interrupt which propagates back to the operating system. In turn, the OS uses this interrupt to return the relevant data back to the user-level process which initiated the request.

![Untitled](I%20O%20Control%2085ea536e94d44e03b7c989b49d02494d/Untitled.png)

- Synchronous I/O
    - The calling process waits while the request is handled by the I/O device.
- Asynchronous I/O
    - The calling process continues to execute while the I/O controller processes the request. This leads to improved system performance since the process can continue to run while the I/O request finished.
    - Upon completion, the I/O device triggers an interrupt which returns the data back to the process.

> In practice, synchronous I/O is often preferred since asynchronous I/O requests can require more complicated programming.
> 
- Memory Mapped I/O
    - device’s own onboard memory is mapped into the processor’s address space. OS reserve a part of the physical memory & put the device manager in that memory.
    - Data to be written to the device is copied by the driver to the device memory, and data read in by the device is available in the shared memory for copying back into the system memory.
    - used by network and video devices.
    - Many adapters offer a combination of programmed I/O and memory-mapped modes, where the data buffers are mapped into the processor’s memory space and the internal device registers that provide status is accessed through the I/O space.
    
    ![https://www.baeldung.com/wp-content/uploads/sites/4/2022/04/MemoryMappedVsPortMapped.png](https://www.baeldung.com/wp-content/uploads/sites/4/2022/04/MemoryMappedVsPortMapped.png)
    
    ## Interrupt-based asynchronous I/O
    
    - The device controller has its own small processor which executes asynchronously with the main CPU.
    - Devices put an interrupt signal on the bus when the IO controller is finished.
    - CPU takes the interrupt
        - Save the critical CPU State (h/w state: registers..)
        - Disable interrupts
        - Save state that the interrupt handler will modify (s/w state)
        - Invoke interrupt handler using the in-memory interrupt vector
        - Restore s/w state
        - Enable interrupts
        - Restore the h/w state and continue the execution of the interrupted process.

## Timers

Timers are useful for triggering the context switches that transfer control of the CPU between different processes. Usually, context-switching algorithms have a timer policy, 100ms or something. 

This also protects the CPU from being hogged. If the process in execution is a CPU-intensive process, the CPU will keep the process in execution. So there is a chance of the process keeping executing for long, making the other process non-responsive. (Preemptive Scheduling)

Timers are implemented using hardware clocks and a hardware interrupt table. A timer can be set by saving a timer value into a special register which is then decremented every millisecond. When the timer runs out, an additional register is checked to determine what code should be triggered, for eg the context switch code or an update to the system clock.

[How do hardware timers work?](https://www.youtube.com/watch?v=g_koa00MBLg)

[Is there a timer in the CPU?](https://stackoverflow.com/questions/13208960/is-there-a-timer-in-the-cpu)

[](https://lemp.io/what-is-timer-interrupt-in-operating-system/)

## Synchronisation

It is very important to coordinate the state among cooperating processes. It’s important because interrupts, for example from asynchronous I/O requests, can arrive at any time and disrupt the running code.

Similarly, multiple processes may need to synchronize access to shared data. Since processes are scheduled at unpredictable times and can be interrupted at will, it can be difficult to safely synchronize this data without hardware support. 

An architecture must provide a guarantee that a short sequence of operations [eg: read, modify, write] execute atomically.

- The idea of **atomic sections**
    - It’s a section of code which must run without any interruption.
    - This is achieved by disabling interrupts prior to starting an atomic section and only enabling them after the code segment is complete.
    - During this time, any incoming interrupts must be queued by the hardware so they can be processed after the atomic section ends
- Hardware-level instructions **test & set**

## Virtual Memory

It’s an abstraction that gives processes the impression that a system has an infinite amount of memory available to it. 

### How???

While a laptop or server may only have 2GB of RAM, virtual memory can be used to allow the OS to start up processes which utilize more memory than this physical limit. 

To achieve this, the OS only loads a portion of each process into memory at once. The remaining memory data for a process is actually stored on the disk while not in use. The OS then swaps data between memory and disk in order to keep the required data loaded into RAM at all times. While this gives the illusion of infinite memory, loading data to and from a disk can significantly decrease the performance of any running applications.

In order to implement the virtual memory abstraction, the underlying hardware must support additional registers and lookup tables. It is called translation lookaside buffer [TLB] for speeding up the lookup.

TLB is a memory cache that stores the recent translations of virtual memory to physical memory. It is used to reduce the time taken to access a user's memory location. It is part of the chip’s memory-management unit [MMU]

![https://media.geeksforgeeks.org/wp-content/uploads/20190225192626/tlb1.jpg](https://media.geeksforgeeks.org/wp-content/uploads/20190225192626/tlb1.jpg)